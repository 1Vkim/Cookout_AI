{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1Vkim/Cookout_AI/blob/main/Untitled24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2rSdvNzJ4gZu"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ23Coqcgz-5"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import requests\n",
        "import http.client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFDpFtcyg26l"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "KLING_API_KEY = userdata.get('KLING_API')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU7xAjMZk1-X"
      },
      "outputs": [],
      "source": [
        "\n",
        "def luma(instructions):\n",
        "\n",
        "\n",
        "  conn = http.client.HTTPSConnection(\"api.piapi.ai\")\n",
        "\n",
        "  payload = {\n",
        "      \"prompt\": f\"Generate a video for the cooking instructions.{instructions}\",\n",
        "      \"expand_prompt\":True\n",
        "\n",
        "  }\n",
        "  headers = {\n",
        "      \"X-API-key\": KLING_API_KEY,\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Accept\": \"application/json\"\n",
        "  }\n",
        "  try:\n",
        "\n",
        "    conn.request(\"POST\", \"/generate\", json.dumps(payload), headers)\n",
        "\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "\n",
        "    if code in data and data[\"code\"] == 200 :\n",
        "      task_id = data[\"task_id\"]\n",
        "      conn.request(\"GET\", f\"/api/luma/v1/video/{task_id}\", headers=headers)\n",
        "      get_data = res.read()\n",
        "      for generation in data and video in data[\"generation\"]:\n",
        "        return video\n",
        "\n",
        "    else:\n",
        "      data = res.read()\n",
        "      print(data.decode(\"utf-8\"))\n",
        "\n",
        "\n",
        "    return data.decode(\"utf-8\")\n",
        "  except exception as e:\n",
        "    return f\"Error: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDN1WpVokVyw"
      },
      "outputs": [],
      "source": [
        "def gemini_chat(ingredients):\n",
        "    model = genai.GenerativeModel(\n",
        "        'gemini-1.5-flash',\n",
        "        generation_config=genai.GenerationConfig(\n",
        "            max_output_tokens=1500,\n",
        "            temperature=0.9,\n",
        "        ))\n",
        "\n",
        "    # Generate content based on the provided ingredients\n",
        "    response = model.generate_content(\n",
        "        f'Give me a dish to cook using these ingredients: {ingredients}',\n",
        "        generation_config=genai.GenerationConfig(stop_sequences=['\\n3'])\n",
        "    )\n",
        "\n",
        "        # Extract the generated text from the first candidate's content.parts.text\n",
        "    if response and response.candidates:\n",
        "        return response.candidates[0].content.parts[0].text  # Accessing the text field\n",
        "    else:\n",
        "        return \"No response generated\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "ha4S3FugeiLM",
        "outputId": "a3cb57dd-2c8d-4dca-f15d-c157bc92e1fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Cooking Instructions: You've got the makings of a classic **Aglio e Olio**! Here's how to make it:\n",
            "\n",
            "**Ingredients:**\n",
            "\n",
            "* 1 pound spaghetti\n",
            "* 1/4 cup extra virgin olive oil\n",
            "* 4-6 cloves garlic, minced\n",
            "* Pinch of red pepper flakes (optional)\n",
            "* 1/2 cup grated Parmesan cheese\n",
            "* Salt and pepper to taste\n",
            "\n",
            "**Instructions:**\n",
            "\n",
            "1. **Cook the spaghetti:** Bring a large pot of salted water to a boil. Add the spaghetti and cook according to package directions, al dente. \n",
            "2. **Prepare the sauce:** While the spaghetti cooks, heat the olive oil in a large skillet over medium heat. Add the minced garlic and red pepper flakes (if using) and cook, stirring frequently, until the garlic is fragrant and lightly golden, about 30 seconds. Be careful not to burn the garlic.\n",
            "Raw response: {\"message\":\"account 7020, you are on Free Plan, Free Plan cannot Luma Pay-as-you-go\"}\n",
            "Video Generation Response: Error: account 7020, you are on Free Plan, Free Plan cannot Luma Pay-as-you-go\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Main loop to take user input and generate video\n",
        "while True:\n",
        "    user_input = input(\"Enter ingredients you have in the pantry (or type 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Goodbye\")\n",
        "        break\n",
        "\n",
        "    # Get cooking instructions from AI\n",
        "    cooking_instructions = gemini_chat(user_input)\n",
        "    return f\"Generated Cooking Instructions: {cooking_instructions}\"\n",
        "\n",
        "    # Generate video\n",
        "    video_response = luma(cooking_instructions)\n",
        "    return f\"Video Generation Response: {video_response}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4fGDzWR1qy9",
        "outputId": "c491dc60-78d1-4320-87aa-eff2ac6b1e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi80OjLNLXCePZzeaESt+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}